{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-16T09:49:36.231079Z",
     "iopub.status.busy": "2020-08-16T09:49:36.230851Z",
     "iopub.status.idle": "2020-08-16T09:49:36.823366Z",
     "shell.execute_reply": "2020-08-16T09:49:36.822932Z",
     "shell.execute_reply.started": "2020-08-16T09:49:36.231058Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1aC_XblzZ6-dyskLnhNIe4HHc_IkbJZaG\n",
      "To: /001/usuarios/ajason08/notebooks/temp_jason/ajnlp_models.py\n",
      "100%|██████████| 6.96k/6.96k [00:00<00:00, 16.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "#get_ipython().magic('reset -f')\n",
    "###### project paths\n",
    "project_name = \"product_class_single_new\"\n",
    "project_path = \"/001/usuarios/ajason08/notebooks/prod_class/\"\n",
    "temp_path = \"/001/usuarios/ajason08/notebooks/temp_jason/\"\n",
    "#!ls \"{project_path}\"\n",
    "#!ls \"{temp_path}\"\n",
    "\n",
    "reloadables = {\n",
    "  \"ajnlp_functions\" : \"1ihLk7IagdfUl5gMV-odGiNyo9qqljNFy\",\n",
    "  \"ajnlp_models\" : \"1aC_XblzZ6-dyskLnhNIe4HHc_IkbJZaG\",\n",
    "  \"ajutil\" : \"176qb4Fh8MBUnlKDjCUFWd7zhpCHVG_mS\",\n",
    "  \"Jpandas\": \"12jzHusu8hummWi4PgwhBsed1-Djs6u6i\"\n",
    "}\n",
    "\n",
    "import gdown\n",
    "def jgdown(drive_id, outpath=\"./\", islist=False):\n",
    "  if islist:\n",
    "    for single_drive_id in drive_id:\n",
    "      url = \"https://drive.google.com/uc?id=\"+single_drive_id\n",
    "      gdown.download(url, outpath, quiet=False)    \n",
    "  else:\n",
    "    url = \"https://drive.google.com/uc?id=\"+drive_id\n",
    "    gdown.download(url, outpath, quiet=False)\n",
    "      \n",
    "import sys, importlib\n",
    "def reloader(to_reload, remote, drive_id=None, output=\"./\"):\n",
    "  try:\n",
    "      if remote: jgdown(drive_id, output)\n",
    "      importlib.reload(sys.modules[to_reload])\n",
    "  except KeyError: \n",
    "      raise ImportError(f\"Module {to_reload} not loaded. Can't reload\"\n",
    "                        f\" or not reload-file found\")  \n",
    "    \n",
    "#jgdown(list(reloadables.values()), outpath=temp_path, islist=True)\n",
    "#jgdown(reloadables['ajutil'], outpath=temp_path)\n",
    "\n",
    "toreaload = \"ajnlp_models\"; reloader(toreaload, remote=True, drive_id=reloadables[toreaload], output= temp_path) \n",
    "\n",
    "## download this notebook as executable script\n",
    "#!jupyter nbconvert --to script product_class_light.ipynb\n",
    "\n",
    "#from IPython import get_ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-16T09:15:04.937120Z",
     "iopub.status.busy": "2020-08-16T09:15:04.936892Z",
     "iopub.status.idle": "2020-08-16T09:15:05.716374Z",
     "shell.execute_reply": "2020-08-16T09:15:05.715545Z",
     "shell.execute_reply.started": "2020-08-16T09:15:04.937099Z"
    }
   },
   "outputs": [],
   "source": [
    "# Jupyter packages\n",
    "from IPython.display import display\n",
    "\n",
    "# Deep learning packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import data, datasets\n",
    "from torchtext.vocab import Vectors as myCustomEmbeddings\n",
    "\n",
    "# specific DL models\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer\n",
    "\n",
    "# scikit packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Auxiliar packages\n",
    "import random, sys\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "# personal algorithms\n",
    "sys.path.append(temp_path)\n",
    "import ajnlp_functions as ajf# such as train, test, score, etc\n",
    "import ajnlp_models as jmodels\n",
    "import ajnlp_models # such as cnn, gru, etc\n",
    "import ajutil # utilities such as stopwatch\n",
    "import Jpandas # pandas convenient function\n",
    "\n",
    "# CNN = ajnlp_models.CNN\n",
    "# GRU = ajnlp_models.GRU\n",
    "# BERTGRU = ajnlp_models.BERTGRU\n",
    "# BERTAlone = ajnlp_models.BERTAlone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-16T09:54:32.180459Z",
     "iopub.status.busy": "2020-08-16T09:54:32.180234Z",
     "iopub.status.idle": "2020-08-16T09:54:32.544788Z",
     "shell.execute_reply": "2020-08-16T09:54:32.544341Z",
     "shell.execute_reply.started": "2020-08-16T09:54:32.180440Z"
    }
   },
   "outputs": [],
   "source": [
    "# logger settings\n",
    "model_filename = project_name + '_model.pt'\n",
    "saved_model_path = temp_path + model_filename\n",
    "# Data loading\n",
    "train_dev_file= project_path +  \"train_dev.csv\"\n",
    "#train_file= project_path + \"DiscriminAtt/training/train.txt\"\n",
    "#dev_file= project_path + \"DiscriminAtt/training/validation.txt\"\n",
    "GOLD = True\n",
    "\n",
    "# environment setting\n",
    "device = torch.device('cuda') # cuda cpu ('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "torch.cuda.set_device(3)\n",
    "SEED = 1234\n",
    "\n",
    "#predictions\n",
    "METRIC_FOCUS = \"fscore\" # loss accuracy fscore #last\n",
    "METRIC_AVERAGE = \"weighted\" # None micro macro weighted\n",
    "\n",
    "# Contextual embedding settings\n",
    "#CONTEXTUAL_EMBED= False # True  False(bert)\n",
    "CONTEXTUAL_MODEL = 'bert-base-uncased'\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(CONTEXTUAL_MODEL)\n",
    "\n",
    "# hyper-parameters\n",
    "hopt = {\n",
    "  \"RUN\": 1,\n",
    "  \"EPOCHS\": 1,\n",
    "  \"VOCAB_SIZE\" : 15_000, #15_000\n",
    "  \"BATCH_SIZE\" : 64, # 64 128(using-bert)\n",
    "  ### Model hyperparameters\n",
    "  # regularization\n",
    "  \"DROPOUT\" : 0.2, # 0.25(gru) 0.5(cnn)\n",
    "  #CNN\n",
    "  \"N_FILTERS\" : 100, #100\n",
    "  \"FILTER_SIZES\" : [2,3],#[2,3,4]\n",
    "  # RNN\n",
    "  \"HIDDEN_DIM\" : 256, # 256 64(cheap-bert)\n",
    "  \"N_LAYERS\" : 1,\n",
    "  \"BIDIRECTIONAL\" : True,\n",
    "  # BERT\n",
    "  \"BERT_FROZEN\" : True,\n",
    "  \"BERT_POOLED\" : False\n",
    "  }\n",
    "BENCHMARK = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-16T09:15:08.626638Z",
     "iopub.status.busy": "2020-08-16T09:15:08.626415Z",
     "iopub.status.idle": "2020-08-16T09:15:16.697342Z",
     "shell.execute_reply": "2020-08-16T09:15:16.696784Z",
     "shell.execute_reply.started": "2020-08-16T09:15:08.626616Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading embeddings\n",
    "embedding_file1 = temp_path + \"w2v_dim128_win1_minc1_epocs_10.w2v\"\n",
    "vec = myCustomEmbeddings(embedding_file1) # \"glove.6B.100d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-08-16T09:14:51.895543Z",
     "iopub.status.idle": "2020-08-16T09:14:51.895725Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_bert_alone2(frozen=True):\n",
    "  bert = BertModel.from_pretrained(CONTEXTUAL_MODEL)\n",
    "  OUTPUT_DIM = len(LABEL.vocab)\n",
    "  \n",
    "  model = BERTAlone2(bert, OUTPUT_DIM, hopt[\"DROPOUT\"])\n",
    "\n",
    "  #freezing bert will reduce many millions of parameters to learn\n",
    "  if frozen: \n",
    "    for name, param in model.named_parameters(): \n",
    "      if name.startswith('bert'): param.requires_grad = False\n",
    "\n",
    "  # criterion and optimizer\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  criterion = criterion.to(device)\n",
    "  optimizer = optim.Adam(model.parameters())\n",
    "  model = model.to(device)\n",
    "  ajf.count_parameters(model)\n",
    "  return model, optimizer, criterion\n",
    "\n",
    "class BERTAlone2(nn.Module):\n",
    "  def __init__(self, bert, output_dim, dropout, frozen=False):      \n",
    "    super().__init__()      \n",
    "    self.bert = bert      \n",
    "    embedding_dim = bert.config.to_dict()['hidden_size']      \n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    self.out = nn.Linear(embedding_dim, output_dim)\n",
    "      \n",
    "  def forward(self, text):                 \n",
    "    embedded = self.bert(text)[0]   \n",
    "    embedded = torch.mean(embedded, 1) # aggregating all wordvectors per sentences\n",
    "    embedded = self.dropout(embedded)  \n",
    "    output = self.out(embedded)      \n",
    "    return output\n",
    "#     #freezing bert will reduce many millions of parameters to learn\n",
    "#     print(frozen)\n",
    "#     if frozen:  \n",
    "#       print(frozen)\n",
    "#       for name, param in self.named_parameters(): \n",
    "#           if name.startswith('bert'): param.requires_grad = False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-08-16T09:14:51.896222Z",
     "iopub.status.idle": "2020-08-16T09:14:51.896406Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def create_cnn():\n",
    "#   # Model: main arguments\n",
    "#   INPUT_DIM = len(TEXT.vocab)\n",
    "#   OUTPUT_DIM = len(LABEL.vocab)\n",
    "#   EMBEDDING_DIM = len(TEXT.vocab.vectors[0])\n",
    "#   PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "#   model = CNN(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, PAD_IDX,\n",
    "#               hopt[\"N_FILTERS\"], hopt[\"FILTER_SIZES\"], hopt[\"DROPOUT\"])\n",
    "#   # initial weights\n",
    "#   UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "#   model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "#   model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "#   model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "#   # criterion and optimizer\n",
    "#   criterion = nn.CrossEntropyLoss()\n",
    "#   criterion = criterion.to(device)\n",
    "#   optimizer = optim.Adam(model.parameters())\n",
    "#   model = model.to(device)\n",
    "  \n",
    "#   return model, optimizer, criterion\n",
    "\n",
    "# def create_gru():\n",
    "#   # Model: main arguments\n",
    "#   INPUT_DIM = len(TEXT.vocab)\n",
    "#   OUTPUT_DIM = len(LABEL.vocab)\n",
    "#   EMBEDDING_DIM = len(TEXT.vocab.vectors[0])\n",
    "\n",
    "#   model = GRU(INPUT_DIM,EMBEDDING_DIM, hopt[\"HIDDEN_DIM\"], hopt[\"N_LAYERS\"], hopt[\"BIDIRECTIONAL\"],\n",
    "#                            hopt[\"DROPOUT\"], OUTPUT_DIM)\n",
    "\n",
    "#   # initial weights\n",
    "#   UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "#   PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "#   model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "#   model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "#   model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "  \n",
    "#   # criterion and optimizer\n",
    "#   criterion = nn.CrossEntropyLoss()\n",
    "#   criterion = criterion.to(device)\n",
    "#   optimizer = optim.Adam(model.parameters())\n",
    "#   model = model.to(device)\n",
    "#   return model, optimizer, criterion\n",
    "\n",
    "# def create_bert_gru(frozen=False):\n",
    "#   bert = BertModel.from_pretrained(CONTEXTUAL_MODEL)\n",
    "#   OUTPUT_DIM = len(LABEL.vocab)\n",
    "  \n",
    "#   model = BERTGRU2(bert, hopt[\"HIDDEN_DIM\"], hopt[\"N_LAYERS\"], hopt[\"BIDIRECTIONAL\"],\n",
    "#                   hopt[\"DROPOUT\"], OUTPUT_DIM)\n",
    "\n",
    "#   #freezing bert will reduce many millions of parameters to learn\n",
    "#   if frozen: \n",
    "#     for name, param in model.named_parameters(): \n",
    "#       if name.startswith('bert'): param.requires_grad = False\n",
    "\n",
    "#   # criterion and optimizer\n",
    "#   criterion = nn.CrossEntropyLoss()\n",
    "#   criterion = criterion.to(device)\n",
    "#   optimizer = optim.Adam(model.parameters())\n",
    "#   model = model.to(device)\n",
    "#   return model, optimizer, criterion\n",
    "\n",
    "# def create_bert_alone(frozen=False):\n",
    "#   bert = BertModel.from_pretrained(CONTEXTUAL_MODEL)\n",
    "#   OUTPUT_DIM = len(LABEL.vocab)\n",
    "  \n",
    "#   model = BERTAlone2(bert, hopt[\"DROPOUT\"], OUTPUT_DIM)\n",
    "\n",
    "#   #freezing bert will reduce many millions of parameters to learn\n",
    "#   if frozen: \n",
    "#     for name, param in model.named_parameters(): \n",
    "#       if name.startswith('bert'): param.requires_grad = False\n",
    "\n",
    "#   # criterion and optimizer\n",
    "#   criterion = nn.CrossEntropyLoss()\n",
    "#   criterion = criterion.to(device)\n",
    "#   optimizer = optim.Adam(model.parameters())\n",
    "#   model = model.to(device)\n",
    "#   return model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-08-16T09:14:51.896967Z",
     "iopub.status.idle": "2020-08-16T09:14:51.897149Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def create_cnn2(input_dim, output_dim, embedding_dim, first_vec, pad_idx, unk_idx,\n",
    "#                 nfilters, filter_sizes, dropout):\n",
    "\n",
    "#   model = CNN(input_dim, output_dim,embedding_dim, pad_idx,\n",
    "#                 nfilters, filter_sizes, dropout)\n",
    "#   # initial weights  \n",
    "#   model.embedding.weight.data.copy_(first_vec)\n",
    "#   model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
    "#   model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
    "#   return model\n",
    "\n",
    "# def create_gru2():\n",
    "#   # Model: main arguments\n",
    "#   INPUT_DIM = len(TEXT.vocab)\n",
    "#   OUTPUT_DIM = len(LABEL.vocab)\n",
    "#   EMBEDDING_DIM = len(TEXT.vocab.vectors[0])\n",
    "\n",
    "#   model = GRU(INPUT_DIM,EMBEDDING_DIM, hopt[\"HIDDEN_DIM\"], hopt[\"N_LAYERS\"], hopt[\"BIDIRECTIONAL\"],\n",
    "#                            hopt[\"DROPOUT\"], OUTPUT_DIM)\n",
    "\n",
    "#   # initial weights\n",
    "#   UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "#   PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "#   model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "#   model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "#   model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "  \n",
    "#   # criterion and optimizer\n",
    "\n",
    "\n",
    "#   return model\n",
    "\n",
    "# def create_bert_gru2(frozen=True):\n",
    "  \n",
    "#   OUTPUT_DIM = len(LABEL.vocab)\n",
    "  \n",
    "#   model = BERTGRU(bert, hopt[\"HIDDEN_DIM\"], hopt[\"N_LAYERS\"], hopt[\"BIDIRECTIONAL\"],\n",
    "#                   hopt[\"DROPOUT\"], OUTPUT_DIM)\n",
    "\n",
    "#   #freezing bert will reduce many millions of parameters to learn\n",
    "#   if frozen: \n",
    "#     for name, param in model.named_parameters(): \n",
    "#       if name.startswith('bert'): param.requires_grad = False\n",
    "\n",
    "#   # criterion and optimizer\n",
    "#   criterion = nn.CrossEntropyLoss()\n",
    "#   criterion = criterion.to(device)\n",
    "#   optimizer = optim.Adam(model.parameters())\n",
    "#   model = model.to(device)\n",
    "#   return model, optimizer, criterion\n",
    "\n",
    "# def create_bert_alone2(frozen=True):\n",
    "#   bert = BertModel.from_pretrained(CONTEXTUAL_MODEL)\n",
    "#   OUTPUT_DIM = len(LABEL.vocab)\n",
    "  \n",
    "#   model = BERTAlone2(bert, OUTPUT_DIM, hopt[\"DROPOUT\"])\n",
    "\n",
    "#   #freezing bert will reduce many millions of parameters to learn\n",
    "#   if frozen: \n",
    "#     for name, param in model.named_parameters(): \n",
    "#       if name.startswith('bert'): param.requires_grad = False\n",
    "\n",
    "#   # criterion and optimizer\n",
    "#   criterion = nn.CrossEntropyLoss()\n",
    "#   criterion = criterion.to(device)\n",
    "#   optimizer = optim.Adam(model.parameters())\n",
    "#   model = model.to(device)\n",
    "#   return model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-16T09:15:16.702395Z",
     "iopub.status.busy": "2020-08-16T09:15:16.702256Z",
     "iopub.status.idle": "2020-08-16T09:15:17.901642Z",
     "shell.execute_reply": "2020-08-16T09:15:17.901120Z",
     "shell.execute_reply.started": "2020-08-16T09:15:16.702378Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, dev_df = Jpandas.row_splitter(train_dev_file,\n",
    "                                               \"dataset\", [\"train\",\"dev\"],\n",
    "                                                path_input=True, sep=\"\\t\")\n",
    "\n",
    "# display(pd.read_csv(train_dev_file, \"\\t\").head(4))\n",
    "# display(train_df.head(4))\n",
    "# display(dev_df.head(4))\n",
    "\n",
    "target_name = \"lvl3\"\n",
    "input_names = [\"description_new\"]\n",
    "column_names= [target_name] + input_names\n",
    "tr_val_dev_datasets, fields = ajf.data_wrap(column_names, [\"label\", \"contextual\"],\n",
    "                                           target_name, train_df, dev_df, SEED,\n",
    "                                           hopt[\"VOCAB_SIZE\"], hopt[\"BATCH_SIZE\"],\n",
    "                                           vec, tokenizer=TOKENIZER)\n",
    "\n",
    "LABEL = fields[target_name]\n",
    "TEXT =  fields[input_names[0]] # first input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-16T09:49:56.787084Z",
     "iopub.status.busy": "2020-08-16T09:49:56.786903Z",
     "iopub.status.idle": "2020-08-16T09:49:56.803400Z",
     "shell.execute_reply": "2020-08-16T09:49:56.802966Z",
     "shell.execute_reply.started": "2020-08-16T09:49:56.787066Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_creation(model_kind, verbosity=False):\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  criterion = criterion.to(device)      \n",
    "  OUTPUT_DIM = len(LABEL.vocab)  \n",
    "  ajf.seed_torch(seed=SEED) # BENCHMARK    \n",
    "  \n",
    "  if \"bert\" in model_kind:\n",
    "    bert = BertModel.from_pretrained(CONTEXTUAL_MODEL)\n",
    "    \n",
    "    if model_kind == \"bert\":      \n",
    "      model = jmodels.BERT_only(bert, OUTPUT_DIM, hopt[\"DROPOUT\"],\n",
    "                                hopt[\"BERT_POOLED\"], hopt[\"BERT_FROZEN\"])\n",
    "    elif model_kind == \"bert_gru\":\n",
    "      model = jmodels.BERTGRU(bert, OUTPUT_DIM,\n",
    "                          hopt[\"HIDDEN_DIM\"], hopt[\"N_LAYERS\"], hopt[\"BIDIRECTIONAL\"],\n",
    "                             hopt[\"DROPOUT\"], hopt[\"BERT_FROZEN\"])          \n",
    "#       return create_bert_gru2()\n",
    "    else: raise ValueError(f'model {model_kind} is not supported')          \n",
    "  \n",
    "  else:  \n",
    "    INPUT_DIM = len(TEXT.vocab)  \n",
    "    EMBEDDING_DIM = len(TEXT.vocab.vectors[0])\n",
    "    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "    FIRST_VEC = TEXT.vocab.vectors    \n",
    "    \n",
    "    if model_kind == \"cnn\": \n",
    "      model = jmodels.CNN(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM,                        \n",
    "                          hopt[\"N_FILTERS\"], hopt[\"FILTER_SIZES\"], hopt[\"DROPOUT\"],\n",
    "                           FIRST_VEC, PAD_IDX, UNK_IDX)\n",
    "    elif model_kind == \"gru\":\n",
    "      model = jmodels.GRU(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM,\n",
    "                          hopt[\"HIDDEN_DIM\"], hopt[\"N_LAYERS\"], hopt[\"BIDIRECTIONAL\"],\n",
    "                             hopt[\"DROPOUT\"],\n",
    "                           FIRST_VEC, PAD_IDX, UNK_IDX)        \n",
    "    else: raise ValueError(f'model {model_kind} is not supported')          \n",
    "  if verbosity: ajf.count_parameters(model)\n",
    "  \n",
    "  optimizer = optim.Adam(model.parameters())\n",
    "  model = model.to(device)  \n",
    "  return model, optimizer, criterion\n",
    "\n",
    "def deploy_experiment(model, optimizer, criterion):\n",
    "\n",
    "  train_iter, valid_iter, dev_iter = data.BucketIterator.splits(\n",
    "    tr_val_dev_datasets,\n",
    "    sort = False,\n",
    "    batch_size = hopt[\"BATCH_SIZE\"],\n",
    "    device = device, \n",
    "    #shuffle=False\n",
    "  )\n",
    "  \n",
    "  train_report = ajf.train_model(model, optimizer, criterion,\n",
    "                                 train_iter, valid_iter,\n",
    "                                 input_names, target_name,\n",
    "                                 saved_model_path, \n",
    "                                 selector= METRIC_FOCUS, avg = METRIC_AVERAGE,\n",
    "                                 epochs=hopt[\"EPOCHS\"], verbosity = False)\n",
    "  \n",
    "  test_report, human_pred = ajf.test_model(model, dev_iter,\n",
    "                                          input_names, target_name,\n",
    "                                          saved_model_path,\n",
    "                                          LABEL.vocab, temp_path,\n",
    "                                          #operations = {\"confusion\",\"class_metrics\", \"average_schemes\"},\n",
    "                                          operations = {\"average_schemes\"},\n",
    "                                          gold=GOLD, verbosity=True)\n",
    "  return train_report, test_report, human_pred\n",
    "\n",
    "def experiment_pipeline(grid_search, key, hopt, model_kind,\n",
    "                       verbosity = True):\n",
    "  runs_report = pd.DataFrame()\n",
    "  watch = ajutil.Stopwatch()\n",
    "  if verbosity: print(\"\\n\".join([f'Starting @ {watch.current_time()} with',\n",
    "                   f'epochs = {hopt[\"EPOCHS\"]};  avg = {METRIC_AVERAGE}'\n",
    "                                ])\n",
    "                     )\n",
    "  for i, parm in enumerate(grid_search):\n",
    "    display(Markdown(f'<hr><b>Run {i+1}/{len(grid_search)}</b>: {key}={parm} from {grid_search}'))\n",
    "    \n",
    "    # These 2 lines are the very important ones for grid_search,\n",
    "    # everything else is for reporting\n",
    "    hopt[key] = parm\n",
    "    train_report, test_report, human_pred = deploy_experiment(*model_creation(model_kind,True))\n",
    "\n",
    "    assert GOLD, \"No gold data, not use this cycle! call your function directly\"\n",
    "    run_time = watch.stop()\n",
    "    if verbosity: print(f'end_run {i+1}/{len(grid_search)}: '\n",
    "                        f'⏲{run_time}, @ {watch.current_time()}'\n",
    "                       )      \n",
    "    \n",
    "    search_report = pd.Series([parm, run_time], index=[key,\"⏲\"])\n",
    "    train_test_report = train_report.append(test_report)\n",
    "    runs_report = runs_report.append(search_report.append(train_test_report),\n",
    "                                     ignore_index=True)\n",
    "\n",
    "  total_report = pd.Series([grid_search, watch.totaltime],\n",
    "                           index=[key,\"⏲\"], name=\"total\")\n",
    "  runs_report = runs_report.append(total_report, ignore_index=True)\n",
    "  runs_report.to_csv(temp_path+\"runs_report\", index=False)\n",
    "  \n",
    "  if verbosity: display(Markdown(\"<hr><H2>FINAL REPORT:\"),\n",
    "                        HTML(runs_report.to_html(index=False))\n",
    "                       )\n",
    "    \n",
    "  return train_report, test_report, human_pred, runs_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-16T09:54:38.106793Z",
     "iopub.status.busy": "2020-08-16T09:54:38.106485Z",
     "iopub.status.idle": "2020-08-16T10:02:09.317485Z",
     "shell.execute_reply": "2020-08-16T10:02:09.316407Z",
     "shell.execute_reply.started": "2020-08-16T09:54:38.106760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting @ 04:54:38 with\n",
      "epochs = 1;  avg = weighted\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<hr><b>Run 1/3</b>: RUN=0 from [0, 1, 2]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 216,089 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/001/usuarios/ajason08/anaconda3/envs/nlp_py369/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**> Average schemes comparison**:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric \\ scheme</th>\n",
       "      <th>micro</th>\n",
       "      <th>macro</th>\n",
       "      <th>weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.318</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.104651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.318</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.318000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fscore</th>\n",
       "      <td>0.318</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.154920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric \\ scheme  micro     macro  weighted\n",
       "precision        0.318  0.002558  0.104651\n",
       "recall           0.318  0.005058  0.318000\n",
       "fscore           0.318  0.002700  0.154920"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_run 1/3: ⏲3m 36s, @ 04:58:15\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<hr><b>Run 2/3</b>: RUN=1 from [0, 1, 2]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 216,089 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/001/usuarios/ajason08/anaconda3/envs/nlp_py369/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**> Average schemes comparison**:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric \\ scheme</th>\n",
       "      <th>micro</th>\n",
       "      <th>macro</th>\n",
       "      <th>weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.318</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.104651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.318</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.318000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fscore</th>\n",
       "      <td>0.318</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.154920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric \\ scheme  micro     macro  weighted\n",
       "precision        0.318  0.002558  0.104651\n",
       "recall           0.318  0.005058  0.318000\n",
       "fscore           0.318  0.002700  0.154920"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_run 2/3: ⏲3m 36s, @ 05:01:51\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<hr><b>Run 3/3</b>: RUN=2 from [0, 1, 2]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 216,089 trainable parameters\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8579532e5633>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# full_reports contains: train_report, test_report, human_pred, runs_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfull_reports\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-b61a9de51df1>\u001b[0m in \u001b[0;36mexperiment_pipeline\u001b[0;34m(grid_search, key, hopt, model_kind, verbosity)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# everything else is for reporting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mhopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mtrain_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeploy_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_kind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mGOLD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No gold data, not use this cycle! call your function directly\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-b61a9de51df1>\u001b[0m in \u001b[0;36mdeploy_experiment\u001b[0;34m(model, optimizer, criterion)\u001b[0m\n\u001b[1;32m     61\u001b[0m                                  \u001b[0msaved_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                                  \u001b[0mselector\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mMETRIC_FOCUS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETRIC_AVERAGE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                                  epochs=hopt[\"EPOCHS\"], verbosity = False)\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   test_report, human_pred = ajf.test_model(model, dev_iter,\n",
      "\u001b[0;32m~/notebooks/temp_jason/ajnlp_functions.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion, train_iterator, valid_iterator, input_f, output_f, saved_model_path, selector, avg, epochs, verbosity)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0mvalid_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/temp_jason/ajnlp_functions.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, input_f, output_f, optimizer, criterion, avg)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavgScheme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0;31m#predictions = model(batch.text_field)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;31m#loss = criterion(predictions, batch.label_field)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/temp_jason/ajnlp_functions.py\u001b[0m in \u001b[0;36mmlscoring\u001b[0;34m(truth, preds, verbosity, avgScheme)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mmax_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get the index of the max probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtruth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# get precision, recall, and f1 using sklearn (the support metric is not needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search, key = list(range(3)), \"RUN\"\n",
    "\n",
    "#grid_search, key = list(range(10,10*5+1,5)), \"EPOCHS\"\n",
    "#grid_search, key = np.arange(0.1, 0.9, 0.1), \"DROPOUT\"\n",
    "#grid_search, key = list(range(16,16*4+1, 16)), \"BATCH_SIZE\"\n",
    "\n",
    "model_kind = \"bert\" #cnn gru bert bert_gru\n",
    "\n",
    "# full_reports contains: train_report, test_report, human_pred, runs_report\n",
    "full_reports = experiment_pipeline(grid_search, key, hopt, model_kind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-08-16T09:14:51.899830Z",
     "iopub.status.idle": "2020-08-16T09:14:51.900009Z"
    }
   },
   "outputs": [],
   "source": [
    "hopt[\"BERT_FROZEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
